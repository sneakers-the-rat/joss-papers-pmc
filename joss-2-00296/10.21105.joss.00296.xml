<?xml version="1.0" encoding="utf-8" ?>
<article>
  <articleinfo>
    <title>kerasR: R Interface to the Keras Deep Learning Library</title>
    <authors>
      <author>
        <name>Taylor B Arnold</name>
        <orcid>0000-0003-0576-0669</orcid>
        <affiliation>
          <orgname>
            1
          </orgname>
        </affiliation>
      </author>
    </authors>
    <tags>
      <tag>neural networks</tag>
      <tag>convolutional neural networks</tag>
      <tag>recurrent neural networks</tag>
      <tag>computer vision</tag>
      <tag>natural language processing</tag>
    </tags>
    <date>01 June 2017</date>
    <paper_doi>10.21105/joss.00296</paper_doi>
    <software_repository>https://github.com/statsmaths/kerasR</software_repository>
    <software_archive>http://dx.doi.org/10.5281/zenodo.814996</software_archive>
    <paper_url>https://github.com/openjournals/joss-papers/raw/master/joss.00296/10.21105.joss.00296.pdf</paper_url>
  </articleinfo>
  <body>
    <h1 id="summary">Summary</h1>
    <p>Keras is a high-level neural networks API, originall written in Python, and capable of running on top of either TensorFlow or Theano. It was developed with a focus on enabling fast experimentation. This package provides an interface to Keras from within R. All of the returned objects from functions in this package are either native R objects or raw pointers to python objects, making it possible for users to access the entire keras API. The main benefits of the package are (1) correct, manual parsing of R inputs to python, (2) R-sided documentation, and (3) examples written using the API. It allows, amongst other things, users to load and run popular pre-trained models such as VGG-19 <span class="citation">(He et al. 2015)</span>, ResNet50 <span class="citation">(He et al. 2016)</span>, and Inception <span class="citation">(Szegedy et al. 2015)</span>.</p>
    <p>Most functions have associated examples showing a working example of how a layer or object may be used. These are mostly toy examples, made with small datasets with little regard to whether these are the correct models for a particular task. See the package vignettes for a more thorough explaination and several larger, more practical examples.</p>
    <h1 id="references" class="unnumbered">References</h1>
    <div id="refs" class="references">
    <div id="ref-he2015delving">
    <p>He, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. “Delving Deep into Rectifiers: Surpassing Human-Level Performance on Imagenet Classification.” In <em>Proceedings of the Ieee International Conference on Computer Vision</em>, 1026–34.</p>
    </div>
    <div id="ref-he2016deep">
    <p>———. 2016. “Deep Residual Learning for Image Recognition.” In <em>Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition</em>, 770–78.</p>
    </div>
    <div id="ref-szegedy2015going">
    <p>Szegedy, Christian, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. 2015. “Going Deeper with Convolutions.” In <em>Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition</em>, 1–9.</p>
    </div>
    </div>
  </body>
</article>
