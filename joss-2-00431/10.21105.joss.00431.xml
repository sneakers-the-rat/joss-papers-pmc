<?xml version="1.0" encoding="utf-8" ?>
<article>
  <articleinfo>
    <title>pyGPGO: Bayesian Optimization for Python</title>
    <authors>
      <author>
        <name>José Jiménez</name>
        <orcid>0000-0002-5335-7834</orcid>
        <affiliation>
          <orgname>
            1
          </orgname>
        </affiliation>
      </author>
      <author>
        <name>Josep Ginebra</name>
        <orcid>0000-0001-9521-9635</orcid>
        <affiliation>
          <orgname>
            2
          </orgname>
        </affiliation>
      </author>
    </authors>
    <tags>
      <tag>machine-learning</tag>
      <tag>bayesian</tag>
      <tag>optimization</tag>
    </tags>
    <date>4 September 2017</date>
    <paper_doi>10.21105/joss.00431</paper_doi>
    <software_repository>https://github.com/hawk31/pyGPGO</software_repository>
    <software_archive>https://doi.org/10.5281/zenodo.1040676</software_archive>
    <paper_url>http://www.theoj.org/joss-papers/joss.00431/10.21105.joss.00431.pdf</paper_url>
  </articleinfo>
  <body>
    <h1 id="summary">Summary</h1>
    <p>Bayesian optimization has risen over the last few years as a very attractive method to optimize expensive to evaluate, black box, derivative-free and possibly noisy functions <span class="citation">(Shahriari et al. 2016)</span>. This framework uses <em>surrogate models</em>, such as the likes of a Gaussian Process <span class="citation">(Rasmussen and Williams 2004)</span> which describe a prior belief over the possible objective functions in order to approximate them. The procedure itself is inherently sequential: our function is first evaluated a few times, a surrogate model is then fit with this information, which will later suggest the next point to be evaluated according to a predefined <em>acquisition function</em>. These strategies typically aim to balance exploitation and exploration, that is, areas where the posterior mean or variance of our surrogate model are high respectively.</p>
    <p>These strategies have recently grabbed the attention of machine learning researchers over simpler black-box optimization strategies, such as grid search or random search <span class="citation">(Bergstra James and Bengio Yoshua 2012)</span>. It is specially interesting in areas such as automatic machine-learning hyperparameter optimization <span class="citation">(Snoek, Larochelle, and Adams 2012)</span>, A/B testing <span class="citation">(Chapelle and Li 2011)</span> or recommender systems <span class="citation">(Vanchinathan et al. 2014)</span>, among others. Furthermore, the framework is entirely modular; there are many choices a user could take regarding the design of the optimization procedure: choice of surrogate model, covariance function, acquisition function behaviour or hyperparameter treatment, to name a few.</p>
    <p>Here we present <em>pyGPGO</em> , an open-source Python package for Bayesian Optimization, which embraces this modularity in its design. While additional Python packages exist for the same purpose, either they are restricted for non-commercial applications <span class="citation">(Snoek 2012)</span>, implement a small subset of the features <span class="citation">(Yelp 2014)</span>, or do not provide a modular interface <span class="citation">(team. 2016)</span>. <em>pyGPGO</em> on the other hand aims to provide the highest degree of freedom in the design and inference of a Bayesian optimization pipeline, while being feature-wise competitive with other existing software. <em>pyGPGO</em> currently supports:</p>
    <ul>
    <li>Different surrogate models: Gaussian Processes, Student-t Processes, Random Forests (&amp; variants) and Gradient Boosting Machines.</li>
    <li>Most usual covariance function structures, as well as their derivatives: squared exponential, Matèrn, gamma-exponential, rational-quadratic, exponential-sine and dot-product kernel.</li>
    <li>Several acquisition function behaviours: probability of improvement, expected improvement, upper confidence bound and entropy-based, as well as their integrated versions.</li>
    <li>Type II maximum-likelihood estimation of covariance hyperparameters.</li>
    <li>MCMC sampling for the full-bayesian treatment of hyperparameters (via <code>pyMC3</code> <span class="citation">(Salvatier, Wiecki, and C. 2016)</span>)</li>
    </ul>
    <p><em>pyGPGO</em> is MIT-licensed and can be retrieved from both <a href="https://github.com/hawk31/pyGPGO">GitHub</a> and <a href="https://pypi.python.org/pypi/pyGPGO/">PyPI</a>, with extensive documentation available at <a href="http://pygpgo.readthedocs.io/en/latest/">ReadTheDocs</a>. <em>pyGPGO</em> is built on top of other well known packages of the Python scientific ecosystem as dependencies, such as numpy, scikit-learn, pyMC3 and theano.</p>
    <div class="figure">
    <img src="franke.gif" alt="pyGPGO in action." />
    <p class="caption">pyGPGO in action.</p>
    </div>
    <h1 id="future-work">Future work</h1>
    <p><em>pyGPGO</em> is an ongoing project, and as such there are several improvements that will be tackled in the near future:</p>
    <ul>
    <li>Support for linear combinations of covariance functions, with automatic gradient computation.</li>
    <li>Support for more diverse acquisition functions, such as Predictive Entropy Search <span class="citation">(Hernández-Lobato, Hoffman, and Ghahramani 2014)</span>.</li>
    <li>A class for constrained Bayesian Optimization is planned for the near future. <span class="citation">(Gardner et al. 2014)</span></li>
    </ul>
    <h1 id="references" class="unnumbered">References</h1>
    <div id="refs" class="references">
    <div id="ref-Bergstra2012">
    <p>Bergstra James, James, and Umontrealca Bengio Yoshua. 2012. “Random Search for Hyper-Parameter Optimization.” <em>Journal of Machine Learning Research</em> 13: 281–305. doi:<a href="https://doi.org/10.1162/153244303322533223">10.1162/153244303322533223</a>.</p>
    </div>
    <div id="ref-Chapelle2011">
    <p>Chapelle, Olivier, and Lihong Li. 2011. “An Empirical Evaluation of Thompson Sampling.” <em>Advances in Neural Information Processing Systems</em>, 2249—–2257. <a href="http://explo.cs.ucl.ac.uk/wp-content/uploads/2011/05/An-Empirical-Evaluation-of-Thompson-Sampling-Chapelle-Li-2011.pdf" class="uri">http://explo.cs.ucl.ac.uk/wp-content/uploads/2011/05/An-Empirical-Evaluation-of-Thompson-Sampling-Chapelle-Li-2011.pdf</a>.</p>
    </div>
    <div id="ref-Gardner2014">
    <p>Gardner, Jacob R., Matt J. Kusner, Zhixiang Eddie Xu, Kilian Q. Weinberger, and John P. Cunningham. 2014. “Bayesian Optimization with Inequality Constraints.” <em>Proceedings of the 31st International Conference on Machine Learning</em> 32: 937–45.</p>
    </div>
    <div id="ref-Hernandez-Lobato2014">
    <p>Hernández-Lobato, José Miguel, Matthew W Hoffman, and Zoubin Ghahramani. 2014. “Predictive Entropy Search for Efficient Global Optimization of Black-box Functions.” <em>Advances in Neural Information Processing Systems 28</em>, 1–9. <a href="https://jmhldotorg.files.wordpress.com/2014/10/pes-final.pdf" class="uri">https://jmhldotorg.files.wordpress.com/2014/10/pes-final.pdf</a>.</p>
    </div>
    <div id="ref-Rasmussen2004">
    <p>Rasmussen, Carl E., and Christopher K. I. Williams. 2004. <em>Gaussian processes for machine learning.</em> Vol. 14. 2. doi:<a href="https://doi.org/10.1142/S0129065704001899">10.1142/S0129065704001899</a>.</p>
    </div>
    <div id="ref-Salvatier2016">
    <p>Salvatier, J, TV Wiecki, and Fonnesbeck C. 2016. “Probabilistic programming in Python using PyMC3.” <em>PeerJ Computer Science</em>. <a href="https://doi.org/10.7717/peerj-cs.55" class="uri">https://doi.org/10.7717/peerj-cs.55</a>.</p>
    </div>
    <div id="ref-Shahriari2016">
    <p>Shahriari, Bobak, Kevin Swersky, Ziyu Wang, Ryan P. Adams, and Nando De Freitas. 2016. “Taking the human out of the loop: A review of Bayesian optimization.” <em>Proceedings of the IEEE</em> 104 (1): 148–75. doi:<a href="https://doi.org/10.1109/JPROC.2015.2494218">10.1109/JPROC.2015.2494218</a>.</p>
    </div>
    <div id="ref-SpearmintSnoek2012">
    <p>Snoek, Jasper. 2012. “Spearmint.” <a href="https://github.com/HIPS/Spearmint" class="uri">https://github.com/HIPS/Spearmint</a>.</p>
    </div>
    <div id="ref-Snoek2012">
    <p>Snoek, Jasper, Hugo Larochelle, and Rp Adams. 2012. “Practical Bayesian optimization of machine learning algorithms.” <em>Advances in Neural Information …</em>, 1–9. doi:<a href="https://doi.org/2012arXiv1206.2944S">2012arXiv1206.2944S</a>.</p>
    </div>
    <div id="ref-scikitoptimize">
    <p>team., The scikit-optimize. 2016. “Scikit-Optimize.” <a href="https://github.com/scikit-optimize/scikit-optimize" class="uri">https://github.com/scikit-optimize/scikit-optimize</a>.</p>
    </div>
    <div id="ref-Vanchinathan2014">
    <p>Vanchinathan, Hastagiri P., Isidor Nikolic, Fabio De Bona, and Andreas Krause. 2014. “Explore-exploit in top-N recommender systems via Gaussian processes.” In <em>Proceedings of the 8th Acm Conference on Recommender Systems - Recsys ’14</em>, 225–32. doi:<a href="https://doi.org/10.1145/2645710.2645733">10.1145/2645710.2645733</a>.</p>
    </div>
    <div id="ref-yelpmoe">
    <p>Yelp. 2014. “MOE.” <a href="https://github.com/Yelp/MOE" class="uri">https://github.com/Yelp/MOE</a>.</p>
    </div>
    </div>
  </body>
</article>
