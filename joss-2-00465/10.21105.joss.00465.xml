<?xml version="1.0" encoding="utf-8" ?>
<article>
  <articleinfo>
    <title>mpnum: A matrix product representation library for Python</title>
    <authors>
      <author>
        <name>Daniel Suess</name>
        <orcid>0000-0002-6354-457X</orcid>
        <affiliation>
          <orgname>
            1
          </orgname>
        </affiliation>
      </author>
      <author>
        <name>Milan Holzäpfel</name>
        <orcid>0000-0002-4687-5027</orcid>
        <affiliation>
          <orgname>
            2
          </orgname>
        </affiliation>
      </author>
    </authors>
    <tags>
      <tag>matrix-product</tag>
      <tag>tensor-train</tag>
      <tag>dmrg</tag>
    </tags>
    <date>10 August 2017</date>
    <paper_doi>10.21105/joss.00465</paper_doi>
    <software_repository>https://github.com/dseuss/mpnum</software_repository>
    <software_archive>http://dx.doi.org/10.5281/zenodo.1115574</software_archive>
    <paper_url>http://www.theoj.org/joss-papers/joss.00465/10.21105.joss.00465.pdf</paper_url>
  </articleinfo>
  <body>
    <h1 id="summary">Summary</h1>
    <p>Tensors – or high-dimensional arrays – are ubiquitous in science and provide the foundation for numerous numerical algorithms in scientific computing, machine learning, signal processing, and other fields. With their high demands in memory and computational time, tensor computations constitute the bottleneck of many such algorithms. This has led to the development of sparse and low-rank tensor decompositions <span class="citation" data-cites="Decompositions">(Kolda and Bader 2009)</span>. One such decomposition, which was first developed under the name <em>“matrix product state”</em> (MPS) in the study of entanglement in quantum physics <span class="citation" data-cites="Werner">(Fannes, Nachtergaele, and Werner 1992)</span>, is the <em>matrix product</em> or <em>tensor train</em> (TT) representation <span class="citation" data-cites="Schollwoeck Oseledets">(Schollwöck 2011; Oseledets 2011)</span>.</p>
    <p>The matrix product tensor format is often used in practice <span class="citation" data-cites="Latorre NMR QuantumChemistry Uncertainty NeuralNetworks Stoudenmire">(Latorre 2005; Savostyanov et al. 2014; Szalay et al. 2015; Zhang et al. 2015; Novikov et al. 2015; Stoudenmire and Schwab 2016)</span> for two reasons: On the one hand, it captures the low-dimensional structure of many problems well. Therefore, it can be used model those problems computationally in an efficient way. On the other hand, the matrix product tensor format also allows for performing crucial tensor operations – such as addition, contraction, or low-rank approximation – efficiently <span class="citation" data-cites="Schollwoeck Oseledets Orus Dance">(Schollwöck 2011; Oseledets 2011; Orús 2014; Bridgeman and Chubb 2017)</span>.</p>
    <p>The library <strong>mpnum</strong> <span class="citation" data-cites="mpnum">(Suess and Holzäpfel 2017)</span> provides a flexible, user-friendly, and expandable toolbox for prototyping algorithms based on the matrix-product tensor format. Its fundamental data structure is the <code>MPArray</code> which represents a tensor with an arbitrary number of dimensions and local structure. Based on the <code>MPArray</code>, <strong>mpnum</strong> implements basic linear algebraic operations such as addition, contraction, approximate eigenvalue computation, etc. as well as specialized matrix-product decomposition operations such as compression or canonicalization. With these facilities, the user can express algorithms in high-level, readable code. Examples from quantum physics include matrix-product state (MPS) and matrix-product operator (MPO) computations, DMRG, low-rank tensor recovery, and efficient quantum state estimation.</p>
    <h1 id="acknowledgements">Acknowledgements</h1>
    <p>The work of DS has been supported by the Excellence Initiative of the German Federal and State Governments (Grants ZUK 81), the ARO under contract W911NF-14-1-0098 (Quantum Characterization, Verification, and Validation), and the DFG projects GRO 4334/1,2 (SPP1798 CoSIP) The work of MH has been supported by an Alexander von Humboldt Professorship, the ERC Synergy grant BioQ, the EU projects QUCHIP, and the US Army Research Office Grant No. W911NF-14-1-0133. We furthermore acknowledge the provision of computational resources by the Regional Computing Center of the University of Cologne (RRZK) through the DFG-funded HPC system CHEOPS, the state of Baden-Württemberg through bwHPC, and the German Research Foundation (DFG) through grant no INST 40/467-1 FUGG.</p>
    <h1 id="references" class="unnumbered">References</h1>
    <div id="refs" class="references">
    <div id="ref-Dance">
    <p>Bridgeman, J. C., and C. T. Chubb. 2017. “Hand-Waving and Interpretive Dance: An Introductory Course on Tensor Networks.” <em>Journal of Physics A: Mathematical and Theoretical</em> 50 (22):223001. <a href="https://doi.org/10.1088/1751-8121/aa6dc3" class="uri">https://doi.org/10.1088/1751-8121/aa6dc3</a>.</p>
    </div>
    <div id="ref-Werner">
    <p>Fannes, M., B. Nachtergaele, and R. F. Werner. 1992. “Finitely Correlated States on Quantum Spin Chains.” <em>Communications in Mathematical Physics</em> 144 (3):443–90. <a href="https://doi.org/10.1007/BF02099178" class="uri">https://doi.org/10.1007/BF02099178</a>.</p>
    </div>
    <div id="ref-Decompositions">
    <p>Kolda, T., and B. Bader. 2009. “Tensor Decompositions and Applications.” <em>SIAM Review</em> 51 (3):455–500. <a href="https://doi.org/10.1137/07070111X" class="uri">https://doi.org/10.1137/07070111X</a>.</p>
    </div>
    <div id="ref-Latorre">
    <p>Latorre, J.I. 2005. “Image Compression and Entanglement.” <em>arXiv Preprint Quant-Ph/0510031</em>. <a href="https://arxiv.org/abs/quant-ph/0510031" class="uri">https://arxiv.org/abs/quant-ph/0510031</a>.</p>
    </div>
    <div id="ref-NeuralNetworks">
    <p>Novikov, A., D. Podoprikhin, A. Osokin, and D. P. Vetrov. 2015. “Tensorizing Neural Networks.” In <em>Advances in Neural Information Processing Systems 28</em>, edited by C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, 442–50. Curran Associates, Inc. <a href="http://papers.nips.cc/paper/5787-tensorizing-neural-networks.pdf" class="uri">http://papers.nips.cc/paper/5787-tensorizing-neural-networks.pdf</a>.</p>
    </div>
    <div id="ref-Orus">
    <p>Orús, R. 2014. “A Practical Introduction to Tensor Networks: Matrix Product States and Projected Entangled Pair States.” <em>Annals of Physics</em> 349:117–58. <a href="https://doi.org/10.1016/j.aop.2014.06.013" class="uri">https://doi.org/10.1016/j.aop.2014.06.013</a>.</p>
    </div>
    <div id="ref-Oseledets">
    <p>Oseledets, I. 2011. “Tensor-Train Decomposition.” <em>SIAM Journal on Scientific Computing</em> 33 (5):2295–2317. <a href="https://doi.org/10.1137/090752286" class="uri">https://doi.org/10.1137/090752286</a>.</p>
    </div>
    <div id="ref-NMR">
    <p>Savostyanov, D.V., S. V. Dolgov, J. M. Werner, and I. Kuprov. 2014. “Exact Nmr Simulation of Protein-Size Spin Systems Using Tensor Train Formalism.” <em>Phys. Rev. B</em> 90 (8). American Physical Society:085139. <a href="https://doi.org/10.1103/PhysRevB.90.085139" class="uri">https://doi.org/10.1103/PhysRevB.90.085139</a>.</p>
    </div>
    <div id="ref-Schollwoeck">
    <p>Schollwöck, U. 2011. “The Density-Matrix Renormalization Group in the Age of Matrix Product States.” <em>Annals of Physics</em>, January 2011 special issue, 326 (1):96–192. <a href="https://doi.org/10.1016/j.aop.2010.09.012" class="uri">https://doi.org/10.1016/j.aop.2010.09.012</a>.</p>
    </div>
    <div id="ref-Stoudenmire">
    <p>Stoudenmire, E., and D. J. Schwab. 2016. “Supervised Learning with Tensor Networks.” In <em>Advances in Neural Information Processing Systems 29</em>, 4799. Curran Associates, Inc. <a href="https://papers.nips.cc/paper/6211-supervised-learning-with-tensor-networks" class="uri">https://papers.nips.cc/paper/6211-supervised-learning-with-tensor-networks</a>.</p>
    </div>
    <div id="ref-mpnum">
    <p>Suess, D., and M. Holzäpfel. 2017. <em>mpnum: Matrix Product Representation Library for Python</em>. <a href="https://github.com/dseuss/mpnum" class="uri">https://github.com/dseuss/mpnum</a>.</p>
    </div>
    <div id="ref-QuantumChemistry">
    <p>Szalay, S., M. Pfeffer, V. Murg, G. Barcza, F. Verstraete, R. Schneider, and Ö. Legeza. 2015. “Tensor Product Methods and Entanglement Optimization for Ab Initio Quantum Chemistry.” <em>International Journal of Quantum Chemistry</em> 115 (19):1342–91. <a href="https://doi.org/10.1002/qua.24898" class="uri">https://doi.org/10.1002/qua.24898</a>.</p>
    </div>
    <div id="ref-Uncertainty">
    <p>Zhang, Z., X. Yang, I. Oseledets, G.E. Karniadakis, and L. Daniel. 2015. “Enabling High-Dimensional Hierarchical Uncertainty Quantification by Anova and Tensor-Train Decomposition.” <em>IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</em> 34 (1). IEEE:63–76. <a href="https://doi.org/10.1109/TCAD.2014.2369505" class="uri">https://doi.org/10.1109/TCAD.2014.2369505</a>.</p>
    </div>
    </div>
  </body>
</article>
