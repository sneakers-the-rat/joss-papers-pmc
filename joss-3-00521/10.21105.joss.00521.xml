<?xml version="1.0" encoding="utf-8" ?>
<article>
  <articleinfo>
    <title>The Experiment Factory: Reproducible Experiment Containers</title>
    <authors>
      <author>
        <name>Vanessa Sochat</name>
        <orcid>0000-0002-4387-3819</orcid>
        <affiliation>
          <orgname>
            1
          </orgname>
        </affiliation>
      </author>
    </authors>
    <tags>
      <tag>containers</tag>
      <tag>docker</tag>
      <tag>psychology</tag>
      <tag>reproducibility</tag>
      <tag>Docker</tag>
    </tags>
    <date>28 November 2017</date>
    <paper_doi>10.21105/joss.00521</paper_doi>
    <software_repository>https://www.github.com/expfactory/expfactory</software_repository>
    <software_archive>http://dx.doi.org/10.5281/zenodo.1117203</software_archive>
    <paper_url>http://www.theoj.org/joss-papers/joss.00521/10.21105.joss.00521.pdf</paper_url>
  </articleinfo>
  <body>
    <h1 id="summary">Summary</h1>
    <p>The Experiment Factory <span class="citation" data-cites="vanessa_sochat_2017_1059119">(V. Sochat 2017)</span> is Open Source software that makes it easy to generate reproducible behavioral experiments. It offers a browsable, and tested <a href="https://expfactory.github.io/experiments/">library</a> of experiments, games, and surveys, support for multiple kinds of databases, and <a href="https://expfactory.github.io/expfactory/">robust documentation</a> for the provided tools. A user interested in deploying a behavioral assessment can simply select a grouping of paradigms from the web interface, and build a container to serve them.</p>
    <figure>
    <img src="img/portal.png" alt="img/portal.png" /><figcaption>img/portal.png</figcaption>
    </figure>
    <h1 id="challenges-with-behavioral-research">Challenges with Behavioral Research</h1>
    <p>The reproducibility crisis <span class="citation" data-cites="Ram2013-km">(Ram 2013, <span class="citation" data-cites="Stodden2010-cu">Stodden (2010)</span>, <span class="citation" data-cites="noauthor_2015-ig">(“Docker-Based Solutions to Reproducibility in Science - Seven Bridges” 2015)</span>, <span class="citation" data-cites="noauthor_undated-sn">(“Science Is in a Reproducibility Crisis: How Do We Resolve It?” n.d.)</span>, <span class="citation" data-cites="Baker_undated-bx">Baker (n.d.)</span>, <span class="citation" data-cites="Open_Science_Collaboration2015-hb">Open Science Collaboration (2015)</span>)</span> has been well met by many efforts <span class="citation" data-cites="Belmann2015-eb">(Belmann et al. 2015, <span class="citation" data-cites="Moreews2015-dy">Moreews et al. (2015)</span>, <span class="citation" data-cites="Boettiger2014-cz">Boettiger (2014)</span>, <span class="citation" data-cites="Santana-Perez2015-wo">Santana-Perez and Pérez-Hernández (2015)</span>, <span class="citation" data-cites="Wandell2015-yt">Wandell et al. (2015)</span>)</span> across scientific disciplines to capture dependencies required for a scientific analysis. Behavioral research is especially challenging, historically due to the need to bring a study participant into the lab, and currently due to needing to develop and validate a well-tested set of paradigms. A common format for these paradigms is a web-based format that can be done on a computer with an internet connection, without one if all resources are provided locally. However, while many great tools exist for creating the web-based paradigms <span class="citation" data-cites="De_Leeuw2015-zw">(Leeuw 2015, <span class="citation" data-cites="McDonnell2012-ns">McDonnell et al. (2012)</span>)</span>, still lacking is assurance that the generated paradigms will be reproducible. Specifically, the following challenges remain:</p>
    <ul>
    <li><strong>Dependencies</strong> such as software, experiment static files, and runtime variables must be captured for reproduciblity.</li>
    <li>Individual experiments and the library must be <strong>version controlled.</strong></li>
    <li>Each experiment could benefit from being maintianed and tested in an <strong>Open Source</strong> fashion. This means that those knowledgable about the paradigm can easily collaborate on code, and others can file issues and ask questions.</li>
    <li>Tools must allow for <strong>flexibility</strong> to allow different libraries (e.g., JavaScript).</li>
    <li>The final product should be <strong>easy to deploy</strong> exactly as the creator intended.</li>
    </ul>
    <p>The early version of the Experiment Factory <span class="citation" data-cites="Sochat2016-pu">(V. V. Sochat et al. 2016)</span> did a good job to develop somewhat modular paradigms, and offered a small set of Python tools to generate local, static batteries from a single repository. Unfortunately, it was severely limited in its ability to scale, and provide reproducible deployments via linux containers <span class="citation" data-cites="Merkel2014-da">(Merkel 2014)</span>. The experiments were required to conform to specific set of software, the lack of containerization meant that installation was challenging and error prone, and importantly, it did not meet the complete set of goals outlined above. While the <code>expfactory-docker</code> <span class="citation" data-cites="noauthor_undated-pi">(V. V. Sochat and Blair, n.d., <span class="citation" data-cites="Sochat2016-pu">V. V. Sochat et al. (2016)</span>)</span> image offered a means to deploy experiments to Amazon Mechanical Turk, it required substantial setup and was primarily developed to meet the specific needs of one lab.</p>
    <figure>
    <img src="img/expfactory.png" alt="img/expfactory.png" /><figcaption>img/expfactory.png</figcaption>
    </figure>
    <h1 id="experiment-container-generation">Experiment Container Generation</h1>
    <p>The software outlined here, “expfactory,” shares little with the original implementation beyond the name. Specifically, it allows for encapsulation of all dependencies and static files required for behavioral experimentation, and flexibility to the user for configuration of the deployment. For usage of a pre-existing experiment container, the user simply needs to run the Docker image. For generation of a new, custom container the generation workflow is typically the following:</p>
    <ul>
    <li><strong>Selection</strong> The user browses a <a href="https://expfactory.github.io/experiments/">library</a> of available experiments, surveys, and games. A preview is available directly in the browser, and data saved to the local machine for inspection. The preview reflects exactly what will be installed into the container.</li>
    <li><strong>Generation</strong> The user selects one or more paradigms to add to the container, and clicks “Generate.” The user runs the command shown in the browser on his or her local machine to produce the custom recipe for the container, called a Dockerfile.</li>
    <li><strong>Building</strong> The user builds the container (and optionally adds the Dockerfile to version control or automated building on Docker Hub) and uses it in production. The same container is then available for others that want to reproduce the experiment.</li>
    </ul>
    <p>At runtime, the user is then able to select deployment customization such as database (MySQL, PostgreSQL, sqlite3, or default of filesystem), and a study identifier.</p>
    <h1 id="experiment-container-usage">Experiment Container Usage</h1>
    <p>Once a container is generated and it’s unique identifier and image layers served in a registry like Docker Hub, it can be cited in a paper with confidence that others can run and reproduce the work simply by using it.</p>
    <p>More information on experiment development and contribution to the expfactory tools, containers, or library is provided at the Experiment Factory <a href="https://expfactory.github.io/expfactory/" target="_blank">official documentation</a>. This is an Open Source project, and so <a href="https://www.github.com/expfactory/expfactory/issues" target="_blank">feedback and contributions</a> are encouraged and welcome.</p>
    <h1 id="references" class="unnumbered">References</h1>
    <div id="refs" class="references">
    <div id="ref-Baker_undated-bx">
    <p>Baker, Monya. n.d. “Over Half of Psychology Studies Fail Reproducibility Test.” <em>Nature News</em>.</p>
    </div>
    <div id="ref-Belmann2015-eb">
    <p>Belmann, Peter, Johannes Dröge, Andreas Bremges, Alice C McHardy, Alexander Sczyrba, and Michael D Barton. 2015. “Bioboxes: Standardised Containers for Interchangeable Bioinformatics Software.” <em>Gigascience</em> 4 (October). gigascience.biomedcentral.com:47. <a href="https://doi.org/10.1186/s13742-015-0087-0" class="uri">https://doi.org/10.1186/s13742-015-0087-0</a>.</p>
    </div>
    <div id="ref-Boettiger2014-cz">
    <p>Boettiger, Carl. 2014. “An Introduction to Docker for Reproducible Research, with Examples from the R Environment,” October. <a href="https://doi.org/10.1145/2723872.2723882" class="uri">https://doi.org/10.1145/2723872.2723882</a>.</p>
    </div>
    <div id="ref-noauthor_2015-ig">
    <p>“Docker-Based Solutions to Reproducibility in Science - Seven Bridges.” 2015. <a href="https://blog.sbgenomics.com/docker-based-solutions-to-reproducibility-in-science/" class="uri">https://blog.sbgenomics.com/docker-based-solutions-to-reproducibility-in-science/</a>.</p>
    </div>
    <div id="ref-De_Leeuw2015-zw">
    <p>Leeuw, Joshua R de. 2015. “JsPsych: A JavaScript Library for Creating Behavioral Experiments in a Web Browser.” <em>Behav. Res. Methods</em> 47 (1):1–12.</p>
    </div>
    <div id="ref-McDonnell2012-ns">
    <p>McDonnell, J V, J B Martin, D B Markant, A Coenen, A S Rich, and T M Gureckis. 2012. “PsiTurk (Version 1.02)[Software]. New York, NY: New York University.”</p>
    </div>
    <div id="ref-Merkel2014-da">
    <p>Merkel, Dirk. 2014. “Docker: Lightweight Linux Containers for Consistent Development and Deployment.” <em>Linux J.</em> Houston, TX: Belltown Media.</p>
    </div>
    <div id="ref-Moreews2015-dy">
    <p>Moreews, François, Olivier Sallou, Hervé Ménager, Yvan Le Bras, Cyril Monjeaud, Christophe Blanchet, and Olivier Collin. 2015. “BioShaDock: A Community Driven Bioinformatics Shared Docker-Based Tools Registry.” <em>F1000Res.</em> 4 (December). ncbi.nlm.nih.gov:1443. <a href="https://doi.org/10.12688/f1000research.7536.1" class="uri">https://doi.org/10.12688/f1000research.7536.1</a>.</p>
    </div>
    <div id="ref-Open_Science_Collaboration2015-hb">
    <p>Open Science Collaboration. 2015. “PSYCHOLOGY. Estimating the Reproducibility of Psychological Science.” <em>Science</em> 349 (6251):aac4716.</p>
    </div>
    <div id="ref-Ram2013-km">
    <p>Ram, Karthik. 2013. “Git Can Facilitate Greater Reproducibility and Increased Transparency in Science.” <em>Source Code Biol. Med.</em> 8 (1):7.</p>
    </div>
    <div id="ref-Santana-Perez2015-wo">
    <p>Santana-Perez, Idafen, and María S Pérez-Hernández. 2015. “Towards Reproducibility in Scientific Workflows: An Infrastructure-Based Approach.” <em>Sci. Program.</em> 2015 (February). Hindawi Publishing Corporation. <a href="https://doi.org/http://dx.doi.org/10.1155/2015/243180" class="uri">https://doi.org/http://dx.doi.org/10.1155/2015/243180</a>.</p>
    </div>
    <div id="ref-noauthor_undated-sn">
    <p>“Science Is in a Reproducibility Crisis: How Do We Resolve It?” n.d. <a href="http://phys.org/news/2013-09-science-crisis.html" class="uri">http://phys.org/news/2013-09-science-crisis.html</a>.</p>
    </div>
    <div id="ref-vanessa_sochat_2017_1059119">
    <p>Sochat, Vanessa. 2017. “expfactory/expfactory: The Experiment Factory (v3.0) Release.” <a href="https://doi.org/10.5281/zenodo.1059119" class="uri">https://doi.org/10.5281/zenodo.1059119</a>.</p>
    </div>
    <div id="ref-noauthor_undated-pi">
    <p>Sochat, Vanessa V, and Ross W. Blair. n.d. “Expfactory-Docker.” Github.</p>
    </div>
    <div id="ref-Sochat2016-pu">
    <p>Sochat, Vanessa V, Ian W Eisenberg, A Zeynep Enkavi, Jamie Li, Patrick G Bissett, and Russell A Poldrack. 2016. “The Experiment Factory: Standardizing Behavioral Experiments.” <em>Front. Psychol.</em> 7 (April). Frontiers.</p>
    </div>
    <div id="ref-Stodden2010-cu">
    <p>Stodden, Victoria. 2010. “The Scientific Method in Practice: Reproducibility in the Computational Sciences,” February. papers.ssrn.com.</p>
    </div>
    <div id="ref-Wandell2015-yt">
    <p>Wandell, B A, A Rokem, L M Perry, G Schaefer, and R F Dougherty. 2015. “Data Management to Support Reproducible Research,” February.</p>
    </div>
    </div>
  </body>
</article>
