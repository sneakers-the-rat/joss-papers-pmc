<?xml version="1.0" encoding="UTF-8"?>
<doi_batch xmlns="http://www.crossref.org/schema/4.4.0" xmlns:ai="http://www.crossref.org/AccessIndicators.xsd" xmlns:rel="http://www.crossref.org/relations.xsd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" version="4.4.0" xsi:schemaLocation="http://www.crossref.org/schema/4.4.0 http://www.crossref.org/schemas/crossref4.4.0.xsd">
  <head>
    <doi_batch_id>7c5109cad7dde7770f24713823992a3c</doi_batch_id>
    <timestamp>20180204211441</timestamp>
    <depositor>
      <depositor_name>JOSS Admin</depositor_name>
      <email_address>admin@theoj.org</email_address>
    </depositor>
    <registrant>The Open Journal</registrant>
  </head>
  <body>
    <journal>
      <journal_metadata>
        <full_title>The Journal of Open Source Software</full_title>
        <abbrev_title>JOSS</abbrev_title>
        <issn media_type="electronic">2475-9066</issn>
        <doi_data>
          <doi>10.21105/joss</doi>
          <resource>http://joss.theoj.org</resource>
        </doi_data>
      </journal_metadata>
      <journal_issue>
        <publication_date media_type="online">
          <month>02</month>
          <year>2018</year>
        </publication_date>
        <journal_volume>
          <volume>3</volume>
        </journal_volume>
        <issue>22</issue>
      </journal_issue>
      <journal_article publication_type="full_text">
        <titles>
          <title>The Experiment Factory: Reproducible Experiment Containers</title>
        </titles>
        <contributors><person_name sequence="first" contributor_role="author"><given_name>Vanessa</given_name><surname>Sochat</surname><ORCID>http://orcid.org/0000-0002-4387-3819</ORCID></person_name></contributors>
        <publication_date>
          <month>02</month>
          <day>04</day>
          <year>2018</year>
        </publication_date>
        <pages>
          <first_page>521</first_page>
        </pages>
        <publisher_item>
          <identifier id_type="doi">10.21105/joss.00521</identifier>
        </publisher_item>
        <ai:program name="AccessIndicators">
          <ai:license_ref applies_to="vor">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="am">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
          <ai:license_ref applies_to="tdm">http://creativecommons.org/licenses/by/4.0/</ai:license_ref>
        </ai:program>
        <rel:program>
          <rel:related_item>
            <rel:description>Software archive</rel:description>
            <rel:inter_work_relation relationship-type="references" identifier-type="doi">http://dx.doi.org/10.5281/zenodo.1117203</rel:inter_work_relation>
          </rel:related_item>
          <rel:related_item>
            <rel:description>GitHub review issue</rel:description>
            <rel:inter_work_relation relationship-type="hasReview" identifier-type="uri">https://github.com/openjournals/joss-reviews/issues/521</rel:inter_work_relation>
          </rel:related_item>
        </rel:program>
        <doi_data>
          <doi>10.21105/joss.00521</doi>
          <resource>http://joss.theoj.org/papers/10.21105/joss.00521</resource>
          <collection property="text-mining">
            <item>
              <resource mime_type="application/pdf">http://www.theoj.org/joss-papers/joss.00521/10.21105.joss.00521.pdf</resource>
            </item>
          </collection>
        </doi_data>
        <citation_list><citation key="ref1"><unstructured_citation>The Scientific Method in Practice: Reproducibility in the Computational Sciences, Stodden, Victoria, Since the 1660’s the scientific method has included reproducibility as a mainstay in its effort to root error from scientific discovery. With the explosive grow, papers.ssrn.com, feb, 2010, 2</unstructured_citation></citation><citation key="ref2"><unstructured_citation>Git can facilitate greater reproducibility and increased transparency in science, Ram, Karthik, Environmental Science, Policy, and Management, University of California, Berkeley, Berkeley, CA 94720, USA. karthik.ram@berkeley.edu., BACKGROUND: Reproducibility is the hallmark of good science. Maintaining a high degree of transparency in scientific reporting is essential not just for gaining trust and credibility within the scientific community but also for facilitating the development of new ideas. Sharing data and computer code associated with publications is becoming increasingly common, motivated partly in response to data deposition requirements from journals and mandates from funders. Despite this increase in transparency, it is still difficult to reproduce or build upon the findings of most scientific publications without access to a more complete workflow. FINDINGS: Version control systems (VCS), which have long been used to maintain code repositories in the software industry, are now finding new applications in science. One such open source VCS, Git, provides a lightweight yet robust framework that is ideal for managing the full suite of research outputs such as datasets, statistical code, figures, lab notes, and manuscripts. For individual researchers, Git provides a powerful way to track and compare versions, retrace errors, explore new approaches in a structured manner, while maintaining a full audit trail. For larger collaborative efforts, Git and Git hosting services make it possible for everyone to work asynchronously and merge their contributions at any time, all the while maintaining a complete authorship trail. In this paper I provide an overview of Git along with use-cases that highlight how this tool can be leveraged to make science more reproducible and transparent, foster new collaborations, and support novel uses., Source Code Biol. Med., 8, 1, 7, feb, 2013, en, 2</unstructured_citation></citation><citation key="ref3"><unstructured_citation>Docker-based solutions to reproducibility in science - Seven Bridges, Seven Bridges, Seven Bridges is launching a toolkit for creating fully portable bioinformatics workflows, using Docker and the Common Workflow Language., jun, 2015, \urlhttps://blog.sbgenomics.com/docker-based-solutions-to-reproducibility-in-science/, Accessed: 2016-12-17, 6</unstructured_citation></citation><citation key="ref4"><unstructured_citation>expfactory-docker, Sochat, Vanessa V and Blair, Ross W., expfactory-docker - container for deploying behavioral psychology experiments, Github</unstructured_citation></citation><citation key="ref5"><unstructured_citation>The Experiment Factory: Standardizing Behavioral Experiments, Sochat, Vanessa V and Eisenberg, Ian W and Enkavi, A Zeynep and Li, Jamie and Bissett, Patrick G and Poldrack, Russell A, The administration of behavioral and experimental paradigms for psychology research is hindered by lack of a coordinated effort to develop and deploy standardized paradigms. While several frameworks (de Leeuw (2015); McDonnell et al. (2012); Mason and Suri (2011); Lange et al. (2015)) have provided infrastructure and methods for individual research groups to develop paradigms, missing is a coordinated effort to develop paradigms linked with a system to easily deploy them. This disorganization leads to redundancy in development, divergent implementations of conceptually identical tasks, disorganized and error-prone code lacking documentation, and difficulty in replication. The ongoing reproducibility crisis in psychology and neuroscience research (Baker (2015); Open Science Collaboration (2015)) highlights the urgency of this challenge: reproducible research in behavioral psychology is conditional on deployment of equivalent experiments. A large, accessible repository of experiments for researchers to develop collaboratively is most efficiently accomplished through an open source framework. Here we present the Experiment Factory, an open source framework for the development and deployment of web-based experiments. The modular infrastructure includes experiments, virtual machines for local or cloud deployment, and an application to drive these components and provide developers with functions and tools for further extension. We release this infrastructure with a deployment (http://www.expfactory.org) that researchers are currently using to run a set of over 80 standardized web-based experiments on Amazon Mechanical Turk. By providing open source tools for both deployment and development, this novel infrastructure holds promise to bring reproducibility to the administration of experiments, and accelerate scientific progress by providing a shared community resource of psychological paradigms., Front. Psychol., Frontiers, 7, apr, 2016, web-experiments; Behavior; Docker; assessment; reproducibility; experiments, 4</unstructured_citation></citation><citation key="ref6"><unstructured_citation>Science is in a reproducibility crisis: How do we resolve it?, Over the past few years, there has been a growing awareness that many experimentally established “facts” don’t seem to hold up to repeated investigation., \urlhttp://phys.org/news/2013-09-science-crisis.html, Accessed: 2015-11-2</unstructured_citation></citation><citation key="ref7"><unstructured_citation>Over half of psychology studies fail reproducibility test, Baker, Monya, Largest replication study to date casts doubt on many published positive results., Nature News</unstructured_citation></citation><citation key="ref8"><unstructured_citation>PSYCHOLOGY. Estimating the reproducibility of psychological science, Open Science Collaboration, Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47% of original effect sizes were in the 95% confidence interval of the replication effect size; 39% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams., Science, 349, 6251, aac4716, aug, 2015, 8</unstructured_citation></citation><citation key="ref9"><doi>10.5281/zenodo.1059119</doi></citation><citation key="ref10"><unstructured_citation>psiTurk (Version 1.02)[Software]. New York, NY: New York University, McDonnell, J V and Martin, J B and Markant, D B and Coenen, A and Rich, A S and Gureckis, T M, 2012</unstructured_citation></citation><citation key="ref11"><unstructured_citation>jsPsych: a JavaScript library for creating behavioral experiments in a Web browser, de Leeuw, Joshua R, Department of Psychological &amp; Brain Science, Cognitive Science Program, Indiana University, Bloomington, IN, USA, jodeleeu@indiana.edu., Online experiments are growing in popularity, and the increasing sophistication of Web technology has made it possible to run complex behavioral experiments online using only a Web browser. Unlike with offline laboratory experiments, however, few tools exist to aid in the development of browser-based experiments. This makes the process of creating an experiment slow and challenging, particularly for researchers who lack a Web development background. This article introduces jsPsych, a JavaScript library for the development of Web-based experiments. jsPsych formalizes a way of describing experiments that is much simpler than writing the entire experiment from scratch. jsPsych then executes these descriptions automatically, handling the flow from one task to another. The jsPsych library is open-source and designed to be expanded by the research community. The project is available online at www.jspsych.org ., Behav. Res. Methods, 47, 1, 1–12, mar, 2015, 3</unstructured_citation></citation><citation key="ref12"><unstructured_citation>Virtual Machines: Versatile Platforms for Systems and Processes, Smith, J E and Nair, R, Morgan Kaufmann Publishers, The Morgan Kaufmann Series in Computer Architecture and Design Series, 2005</unstructured_citation></citation><citation key="ref13"><unstructured_citation>Docker: Lightweight Linux Containers for Consistent Development and Deployment, Merkel, Dirk, Linux J., Belltown Media, 2014, 239, mar, 2014, Houston, TX, 3</unstructured_citation></citation><citation key="ref14"><unstructured_citation>Docker-based solutions to reproducibility in science - Seven Bridges, Seven Bridges, Seven Bridges is launching a toolkit for creating fully portable bioinformatics workflows, using Docker and the Common Workflow Language., jun, 2015, \urlhttps://blog.sbgenomics.com/docker-based-solutions-to-reproducibility-in-science/, Accessed: 2016-12-17, 6</unstructured_citation></citation><citation key="ref15"><doi>https://doi.org/10.1007/978-3-319-31744-1_52</doi></citation><citation key="ref16"><doi>10.12688/f1000research.7536.1</doi></citation><citation key="ref17"><doi>10.1186/s13742-015-0087-0</doi></citation><citation key="ref18"><doi>10.1145/2723872.2723882</doi></citation><citation key="ref19"><doi>http://dx.doi.org/10.1155/2015/243180</doi></citation><citation key="ref20"><unstructured_citation>Data management to support reproducible research, Wandell, B A and Rokem, A and Perry, L M and Schaefer, G and Dougherty, R F, We describe the current state and future plans for a set of tools for scientific data management (SDM) designed to support scientific transparency and reproducible research. SDM has been in active use at our MRI Center for more than two years. We designed the system to be used from the beginning of a research project, which contrasts with conventional end-state databases that accept data as a project concludes. A number of benefits accrue from using scientific data management tools early and throughout the project, including data integrity as well as reuse of the data and of computational methods., feb, 2015, arXiv, q-bio.QM, 1502.06900, 2</unstructured_citation></citation></citation_list>
      </journal_article>
    </journal>
  </body>
</doi_batch>
