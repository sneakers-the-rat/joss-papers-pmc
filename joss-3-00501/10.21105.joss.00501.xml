<?xml version="1.0" encoding="utf-8" ?>
<article>
  <articleinfo>
    <title>Category Encoders: a scikit-learn-contrib package of transformers for encoding categorical data</title>
    <authors>
      <author>
        <name>William D McGinnis</name>
        <orcid>0000-0002-3009-9465</orcid>
        <affiliation>
          <orgname>
            1, 2
          </orgname>
        </affiliation>
      </author>
      <author>
        <name>Chapman Siu</name>
        <orcid>0000-0002-2089-3796</orcid>
        <affiliation>
          <orgname>
            3
          </orgname>
        </affiliation>
      </author>
      <author>
        <name>Andre S</name>
        <orcid>0000-0001-5104-0465</orcid>
        <affiliation>
          <orgname>
            4
          </orgname>
        </affiliation>
      </author>
      <author>
        <name>Hanyu Huang</name>
        <orcid>0000-0001-8503-1014</orcid>
        <affiliation>
          <orgname>
            5
          </orgname>
        </affiliation>
      </author>
    </authors>
    <tags>
      <tag>machine learning</tag>
      <tag>python</tag>
      <tag>sckit-learn</tag>
    </tags>
    <date>5 December 2017</date>
    <paper_doi>10.21105/joss.00501</paper_doi>
    <software_repository>https://github.com/scikit-learn-contrib/categorical-encoding</software_repository>
    <software_archive>http://dx.doi.org/10.5281/zenodo.1157110</software_archive>
    <paper_url>http://www.theoj.org/joss-papers/joss.00501/10.21105.joss.00501.pdf</paper_url>
  </articleinfo>
  <body>
    <h1 id="summary">Summary</h1>
    <p>Category_encoders is a scikit-learn-contrib module of transformers for encoding categorical data. As a scikit-learn-contrib module, category_encoders is fully compatible with the scikit-learn API <span class="citation" data-cites="scikit-learn-api">(Buitinck et al. 2013)</span>. It also uses heavily the tools provided by scikit-learn <span class="citation" data-cites="scikit-learn">(Pedregosa et al. 2011)</span> itself, scipy<span class="citation" data-cites="scipy">(Jones et al. 2001–2001--)</span>, pandas<span class="citation" data-cites="pandas">(McKinney 2010)</span>, and statsmodels<span class="citation" data-cites="statsmodels">(Seabold and Perktold 2010)</span>.</p>
    <p>Categorical variables (wiki) are those that represent a fixed number of possible values, rather than a continuous number. Each value assigns the measurement to one of those finite groups, or categories. They differ from ordinal variables in that the distance from one category to another ought to be equal regardless of the number of categories, as opposed to ordinal variables which have some intrinsic ordering. As an example:</p>
    <p>Ordinal: low, medium, high Categorical: Georgia, Alabama, South Carolina, … , New York</p>
    <p>The machine learning algorithms we will later use tend to want numbers, and not strings, as their inputs so we need some method of coding to convert them.</p>
    <p>Category_encoders includes a number of pre-existing encoders that are commonly used, notably Ordinal, Hashing and OneHot encoders <span class="citation" data-cites="idre">(“R Library Contrast Coding Systems for Categorical Variables,” n.d.)</span><span class="citation" data-cites="carey">(Carey 2003)</span><span class="citation" data-cites="hashing">(Weinberger et al. 2009)</span>. There are also some less frequently used encoders including Backward Difference, Helmert, Polynomial and Sum encoding <span class="citation" data-cites="idre">(“R Library Contrast Coding Systems for Categorical Variables,” n.d.)</span><span class="citation" data-cites="carey">(Carey 2003)</span>. Finally there are experimental encoders: LeaveOneOut, Binary and BaseN <span class="citation" data-cites="zhang">(Zhang, n.d.)</span><span class="citation" data-cites="onehot">(McGinnis 2016a)</span><span class="citation" data-cites="basen">(McGinnis 2016b)</span>.</p>
    <p>The goal of these sorts of transforms is to represent categorical data, which has no true order, as numeric values while balancing desires to keep the representation in as few dimensions as possible. Category_encoders seeks to provide access to the many methodologies for accomplishing such tasks in a simple to use, well tested, and production ready package.</p>
    <h1 id="references" class="unnumbered">References</h1>
    <div id="refs" class="references">
    <div id="ref-scikit-learn-api">
    <p>Buitinck, Lars, Gilles Louppe, Mathieu Blondel, Fabian Pedregosa, Andreas Mueller, Olivier Grisel, Vlad Niculae, et al. 2013. “API Design for Machine Learning Software: Experiences from the Scikit-Learn Project.” <em>arXiv Preprint arXiv:1309.0238</em>.</p>
    </div>
    <div id="ref-carey">
    <p>Carey, Gregory. 2003. “Coding Categorical Variables (Http://Psych.colorado.edu/ Carey/Courses/Psyc5741/Handouts/Coding.”</p>
    </div>
    <div id="ref-scipy">
    <p>Jones, Eric, Travis Oliphant, Pearu Peterson, and others. 2001–2001--. “SciPy: Open Source Scientific Tools for Python.” <a href="http://www.scipy.org/" class="uri">http://www.scipy.org/</a>.</p>
    </div>
    <div id="ref-onehot">
    <p>McGinnis, William D. 2016a. “Beyond One-Hot: An Exploration of Categorical Variables.” <em>Will’s Noise</em>. <a href="http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/" class="uri">http://www.willmcginnis.com/2015/11/29/beyond-one-hot-an-exploration-of-categorical-variables/</a>.</p>
    </div>
    <div id="ref-basen">
    <p>———. 2016b. <em>Will’s Noise</em>. <a href="http://www.willmcginnis.com/2016/12/18/basen-encoding-grid-search-category_encoders/" class="uri">http://www.willmcginnis.com/2016/12/18/basen-encoding-grid-search-category_encoders/</a>.</p>
    </div>
    <div id="ref-pandas">
    <p>McKinney, Wes. 2010. “Data Structures for Statistical Computing in Python.” In <em>Proceedings of the 9th Python in Science Conference</em>, edited by Stéfan van der Walt and Jarrod Millman, 51–56.</p>
    </div>
    <div id="ref-scikit-learn">
    <p>Pedregosa, Fabian, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, et al. 2011. “Scikit-Learn: Machine Learning in Python.” <em>The Journal of Machine Learning Research</em> 12. JMLR. org:2825–30.</p>
    </div>
    <div id="ref-idre">
    <p>“R Library Contrast Coding Systems for Categorical Variables.” n.d. <em>IDRE Stats</em>. <a href="https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/" class="uri">https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/</a>.</p>
    </div>
    <div id="ref-statsmodels">
    <p>Seabold, Skipper, and Josef Perktold. 2010. “Statsmodels: Econometric and Statistical Modeling with Python.” In <em>9th Python in Science Conference</em>.</p>
    </div>
    <div id="ref-hashing">
    <p>Weinberger, Kilian, Anirban Dasgupta, John Langford, Alex Smola, and Josh Attenberg. 2009. “Feature Hashing for Large Scale Multitask Learning.” <em>Proceedings of the 26th Annual International Conference on Machine Learning - ICML 09</em>. <a href="https://doi.org/10.1145/1553374.1553516" class="uri">https://doi.org/10.1145/1553374.1553516</a>.</p>
    </div>
    <div id="ref-zhang">
    <p>Zhang, Owen. n.d. “Strategies to Encode Categorical Variables with Many Categories.” <em>Caterpillar Tube Pricing | Kaggle</em>. <a href="https://www.kaggle.com/c/caterpillar-tube-pricing/discussion/15748#143154" class="uri">https://www.kaggle.com/c/caterpillar-tube-pricing/discussion/15748#143154</a>.</p>
    </div>
    </div>
  </body>
</article>
