<?xml version="1.0" encoding="utf-8" ?>
<article>
  <articleinfo>
    <title>MatDL: A Lightweight Deep Learning Library in MATLAB</title>
    <authors>
      <author>
        <name>Haytham M. Fayek</name>
        <orcid>0000-0002-1840-7605</orcid>
        <affiliation>
          <orgname>
            1
          </orgname>
        </affiliation>
      </author>
    </authors>
    <tags>
      <tag>Machine Learning</tag>
      <tag>Deep Learning</tag>
      <tag>Neural Networks</tag>
    </tags>
    <date>16 September 2017</date>
    <paper_doi>10.21105/joss.00413</paper_doi>
    <software_repository>https://github.com/haythamfayek/MatDL</software_repository>
    <software_archive>http://dx.doi.org/10.5281/zenodo.1042860</software_archive>
    <paper_url>http://www.theoj.org/joss-papers/joss.00413/10.21105.joss.00413.pdf</paper_url>
  </articleinfo>
  <body>
    <h1 id="summary">Summary</h1>
    <p><em>MatDL</em> <span class="citation">(Fayek 2017)</span> is an open-source lightweight deep learning <span class="citation">(LeCun, Bengio, and Hinton 2015; Goodfellow, Bengio, and Courville 2016)</span> library native in MATLAB that implements some most commonly used deep learning algorithms. The library comprises functions that implement the following: (1) basic building blocks of modern neural networks such as affine transformations, convolutions, nonlinear operations, dropout, batch normalization, etc.; (2) popular architectures such as deep neural networks (DNNs), convolutional neural networks (ConvNets), and recurrent neural networks (RNNs) and their variant, the long short-term memory (LSTM) RNNs; (3) optimizers such stochastic gradient descent (SGD), RMSProp and ADAM; as well as (4) boilerplate functions for training, gradients checking, etc. Most of these functions can run on a CPU or a MATLAB-compatible CUDA-enabled GPU. It is straight forward to use the low-level functions to experiment with or test new architectures or training algorithms, or alternatively use the provided models for applied deep learning research.</p>
    <p><em>MatDL</em> was inspired by Stanford's CS231n <span class="citation">(Fei-Fei and others 2017)</span> and Torch <span class="citation">(Collobert, Kavukcuoglu, and Farabet 2011)</span>, and is conceptually similar to Keras <span class="citation">(Chollet and others 2015)</span> and Lasagne <span class="citation">(Dieleman et al. 2015)</span>, but unlike these libraries, it is natively implemented in MATLAB. This makes it convenient in cases where MATLAB is preferred, or if it is required to be closely linked with other libraries written in MATLAB or Octave. <em>MatDL</em> is ideal for rapid machine learning research and experimentation, specially with small datasets, as it was designed with an emphasis on modularity, flexibility and extensibility.</p>
    <p><em>MatDL</em> is MIT-licensed and can be retrieved from <a href="https://github.com/haythamfayek/MatDL">GitHub</a> (https://github.com/haythamfayek/MatDL).</p>
    <h1 id="references" class="unnumbered">References</h1>
    <div id="refs" class="references">
    <div id="ref-Chollet2015">
    <p>Chollet, François, and others. 2015. “Keras.” <a href="https://github.com/fchollet/keras" class="uri">https://github.com/fchollet/keras</a>; GitHub.</p>
    </div>
    <div id="ref-Collobert2011">
    <p>Collobert, Ronan, Koray Kavukcuoglu, and Clément Farabet. 2011. “Torch7: A Matlab-Like Environment for Machine Learning.” In <em>BigLearn, Nips Workshop</em>. EPFL-CONF-192376.</p>
    </div>
    <div id="ref-Lasagne2015">
    <p>Dieleman, Sander, Jan Schlüter, Colin Raffel, Eben Olson, Søren Kaae Sønderby, Daniel Nouri, and others. 2015. “Lasagne: First Release.” doi:<a href="https://doi.org/10.5281/zenodo.27878">10.5281/zenodo.27878</a>.</p>
    </div>
    <div id="ref-Fayek2017">
    <p>Fayek, Haytham M. 2017. “MatDL: A Lightweight Deep Learning Library in Matlab.” <a href="https://github.com/haythamfayek/MatDL" class="uri">https://github.com/haythamfayek/MatDL</a>.</p>
    </div>
    <div id="ref-CS231n">
    <p>Fei-Fei, Li, and others. 2017. “CS231n: Convolutional Neural Networks for Visual Recognition.” <a href="http://cs231n.github.io" class="uri">http://cs231n.github.io</a>.</p>
    </div>
    <div id="ref-Goodfellow2016">
    <p>Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. <em>Deep Learning</em>. MIT Press.</p>
    </div>
    <div id="ref-LeCun2015">
    <p>LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. 2015. “Deep Learning.” <em>Nature</em> 521 (7553). Nature Research: 436–44.</p>
    </div>
    </div>
  </body>
</article>
