<?xml version="1.0" encoding="utf-8" ?>
<article>
  <articleinfo>
    <title>hdbscan: Hierarchical density based clustering</title>
    <authors>
      <author>
        <name>Leland McInnes</name>
        <orcid>0000-0003-2143-6834</orcid>
        <affiliation>
          <orgname>
            1
          </orgname>
        </affiliation>
      </author>
      <author>
        <name>John Healy</name>
        <affiliation>
          <orgname>
            1
          </orgname>
        </affiliation>
      </author>
      <author>
        <name>Steve Astels</name>
        <affiliation>
          <orgname>
            2
          </orgname>
        </affiliation>
      </author>
    </authors>
    <tags>
      <tag>clustering</tag>
      <tag>unsupervised learning</tag>
      <tag>machine learning</tag>
    </tags>
    <date>26 February 2017</date>
    <paper_doi>10.21105/joss.00205</paper_doi>
    <software_repository>https://github.com/scikit-learn-contrib/hdbscan</software_repository>
    <software_archive>http://dx.doi.org/10.5281/zenodo.401403</software_archive>
    <paper_url>https://github.com/openjournals/joss-papers/raw/master/joss.00205/10.21105.joss.00205.pdf</paper_url>
  </articleinfo>
  <body>
    <h1 id="summary">Summary</h1>
    <p>HDBSCAN: Hierarchical Density-Based Spatial Clustering of Applications with Noise <span class="citation">(Campello, Moulavi, and Sander 2013)</span>, <span class="citation">(Campello et al. 2015)</span>. Performs DBSCAN over varying epsilon values and integrates the result to find a clustering that gives the best stability over epsilon. This allows HDBSCAN to find clusters of varying densities (unlike DBSCAN), and be more robust to parameter selection. The library also includes support for Robust Single Linkage clustering <span class="citation">(Chaudhuri et al. 2014)</span>, <span class="citation">(Chaudhuri and Dasgupta 2010)</span>, GLOSH outlier detection <span class="citation">(Campello et al. 2015)</span>, and tools for visualizing and exploring cluster structures. Finally support for prediction and soft clustering is also available.</p>
    <p>-<img src="hdbscan_clustering_result.png" alt="Example clustering results." /> -<img src="hdbscan_condensed_tree.png" alt="Hierarchical tree structure." /></p>
    <h1 id="references" class="unnumbered">References</h1>
    <div id="refs" class="references">
    <div id="ref-campello2013density">
    <p>Campello, Ricardo JGB, Davoud Moulavi, and Joerg Sander. 2013. “Density-Based Clustering Based on Hierarchical Density Estimates.” In <em>Pacific-Asia Conference on Knowledge Discovery and Data Mining</em>, 160–72. Springer. doi:<a href="https://doi.org/10.1007/978-3-642-37456-2_14">10.1007/978-3-642-37456-2_14</a>.</p>
    </div>
    <div id="ref-campello2015hierarchical">
    <p>Campello, Ricardo JGB, Davoud Moulavi, Arthur Zimek, and Jörg Sander. 2015. “Hierarchical Density Estimates for Data Clustering, Visualization, and Outlier Detection.” <em>ACM Transactions on Knowledge Discovery from Data (TKDD)</em> 10 (1). ACM: 5. doi:<a href="https://doi.org/10.1145/2733381">10.1145/2733381</a>.</p>
    </div>
    <div id="ref-chaudhuri2010rates">
    <p>Chaudhuri, Kamalika, and Sanjoy Dasgupta. 2010. “Rates of Convergence for the Cluster Tree.” In <em>Proceedings of the 23rd International Conference on Neural Information Processing Systems</em>, 343–51. NIPS’10. USA: Curran Associates Inc. <a href="https://papers.nips.cc/paper/4068-rates-of-convergence-for-the-cluster-tree" class="uri">https://papers.nips.cc/paper/4068-rates-of-convergence-for-the-cluster-tree</a>.</p>
    </div>
    <div id="ref-chaudhuri2014consistent">
    <p>Chaudhuri, Kamalika, Sanjoy Dasgupta, Samory Kpotufe, and Ulrike von Luxburg. 2014. “Consistent Procedures for Cluster Tree Estimation and Pruning.” <em>IEEE Transactions on Information Theory</em> 60 (12). IEEE: 7900–7912. doi:<a href="https://doi.org/10.1109/TIT.2014.2361055">10.1109/TIT.2014.2361055</a>.</p>
    </div>
    </div>
  </body>
</article>
